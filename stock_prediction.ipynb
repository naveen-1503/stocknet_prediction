{"cells":[{"cell_type":"code","execution_count":1,"id":"b3caea15","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17977,"status":"ok","timestamp":1716527343457,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"b3caea15","outputId":"9ea2c943-8bb2-4bca-93da-da8458219302"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["import os\n","import pandas as pd\n","!pip install textblob\n","from textblob import TextBlob\n","import json\n","!pip install torch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"id":"c02a417c","metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1716527343459,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"c02a417c"},"outputs":[],"source":["# Function to get all of the stock price data\n","def get_stock_prices(stocks_folder_path):\n","    stock_dfs = []\n","\n","    # Iterate through each CSV file in the folder\n","    for filename in os.listdir(stocks_folder_path):\n","        if filename.endswith(\".csv\"):\n","\n","            # Read the CSV file and append to the list\n","            stock_df = pd.read_csv(os.path.join(stocks_folder_path, filename))\n","\n","            #Add name of the stock\n","            stock_name = filename[:-4]\n","            stock_df['Stock'] = stock_name\n","\n","            stock_dfs.append(stock_df)\n","\n","    # Concatenate all DataFrames into a single DataFrame\n","    all_stocks_df = pd.concat(stock_dfs, ignore_index=True)\n","    return all_stocks_df\n"]},{"cell_type":"code","execution_count":3,"id":"3b98d8e6","metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1716527343459,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"3b98d8e6"},"outputs":[],"source":["# Function to preprocess stock price data\n","def preprocess_stock_prices(stock_price_df):\n","    stock_price = stock_price_df[['Stock', 'Date', 'Open', 'Close', 'Adj Close']].copy()\n","    return stock_price"]},{"cell_type":"code","execution_count":4,"id":"446536c2","metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1716527343460,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"446536c2"},"outputs":[],"source":["\n","# Function to preprocess tweet data\n","def preprocess_tweets(tweets_folder_path):\n","    processed_tweets = []\n","    for root, dirs, files in os.walk(tweets_folder_path):\n","        for file in files:\n","            stock_name = os.path.basename(root)\n","            if file.endswith(\".json\"):\n","                file_path = os.path.join(root, file)\n","                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                    for line in f:\n","                        try:\n","                            tweet = json.loads(line)\n","                            processed_tweet = {\n","                                \"Stock\": stock_name,\n","                                \"Date\": tweet.get(\"created_at\", \"\"),\n","                                \"text\": tweet.get(\"text\", \"\"),\n","                                \"user\": tweet.get(\"user\", {}).get(\"screen_name\", \"\"),\n","                                \"lang\": tweet.get(\"lang\", \"\"),\n","                                \"sentiment\": get_sentiment(tweet[\"text\"])\n","                            }\n","\n","                            processed_tweets.append(processed_tweet)\n","                        except json.JSONDecodeError:\n","                            # Handle invalid JSON lines\n","                            print(f\"Invalid JSON in file: {file_path}\")\n","                            continue\n","\n","    tweets_df = pd.DataFrame(processed_tweets)\n","\n","    # Convert the 'datetime' column to datetime format\n","    tweets_df['Date'] = pd.to_datetime(tweets_df['Date'])\n","\n","    # Create separate 'date' and 'time' columns\n","    tweets_df['Time'] = tweets_df['Date'].dt.time\n","    tweets_df['Date'] = tweets_df['Date'].dt.date\n","\n","\n","    return tweets_df\n"]},{"cell_type":"code","execution_count":5,"id":"e9ee88ea","metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1716527343460,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"e9ee88ea"},"outputs":[],"source":["# Function to perform sentiment analysis on tweet text\n","def get_sentiment(tweet):\n","    analysis = TextBlob(tweet)\n","    if analysis.sentiment.polarity > 0:\n","        return 'positive'\n","    elif analysis.sentiment.polarity < 0:\n","        return 'negative'\n","    else:\n","        return 'neutral'"]},{"cell_type":"code","execution_count":6,"id":"b6f5c191","metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1716527343461,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"b6f5c191"},"outputs":[],"source":["# Define LSTM model\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        lstm_out, _ = self.lstm(x)\n","        output = self.fc(lstm_out[:, -1, :])\n","        return output\n"]},{"cell_type":"code","execution_count":7,"id":"TqHo15cMcOM7","metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1716527343461,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"TqHo15cMcOM7"},"outputs":[],"source":["# Define Gru model\n","class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(GRUModel, self).__init__()\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        gru_out, _ = self.gru(x)\n","        output = self.fc(gru_out[:, -1, :])  # Get the last time step output\n","        return output"]},{"cell_type":"code","execution_count":8,"id":"CCsft5uGcj8c","metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1716527343461,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"CCsft5uGcj8c"},"outputs":[],"source":["# Define Transformer Model\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_heads, num_encoder_layers, num_decoder_layers, output_size):\n","        super(TransformerModel, self).__init__()\n","        self.transformer = nn.Transformer(d_model=hidden_size, nhead=num_heads, num_encoder_layers=num_encoder_layers,\n","                                          num_decoder_layers=num_decoder_layers, batch_first=True)\n","        self.fc_in = nn.Linear(input_size, hidden_size)  # Adjust input size to hidden size\n","        self.fc_out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, src):\n","        src = self.fc_in(src)\n","        output = self.transformer(src, src)  # For simplicity, using src as both src and tgt\n","        output = self.fc_out(output[:, -1, :])  # Output of the last token\n","        return output"]},{"cell_type":"code","execution_count":9,"id":"8568e4b0","metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1716527343462,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"8568e4b0"},"outputs":[],"source":["# Define function to train LSTM model\n","def train_model(model, train_loader, criterion, optimizer, num_epochs):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for i, (inputs, labels) in enumerate(train_loader):\n","            try:\n","\n","                optimizer.zero_grad()\n","                output = model(inputs)\n","\n","                # Flatten labels to ensure they have the correct shape\n","                labels = labels.view(-1, 1)\n","\n","                loss = criterion(output, labels)\n","\n","                loss.backward()\n","                optimizer.step()\n","                running_loss += loss.item()\n","            except Exception as e:\n","                print(f'Error in batch {i+1} of epoch {epoch+1}: {e}')\n","                raise e  # Reraise the exception after printing to stop execution\n","\n","        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, running_loss / len(train_loader)))\n"]},{"cell_type":"code","execution_count":25,"id":"7285d249","metadata":{"executionInfo":{"elapsed":721,"status":"ok","timestamp":1716530943454,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"7285d249"},"outputs":[],"source":["# Define function to evaluate model\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            predictions.extend(outputs.detach().numpy())\n","            actuals.extend(labels.numpy())\n","    return np.array(predictions), np.array(actuals)\n",""]},{"cell_type":"code","execution_count":11,"id":"a6010bd4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210716,"status":"ok","timestamp":1716527554140,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"a6010bd4","outputId":"b8af28f2-aaca-4cd2-f881-4dc62ff7c0af"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-d79959972168>:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  tweets_df['Date'] = pd.to_datetime(tweets_df['Date'])\n"]}],"source":["# Define paths\n","stocks_folder_path = \"price/raw/\"\n","tweets_folder_path = \"tweet/raw/\"\n","\n","stock_prices = get_stock_prices(stocks_folder_path)\n","\n","# Preprocess data\n","stock_prices = preprocess_stock_prices(stock_prices)\n","tweet_data = preprocess_tweets(tweets_folder_path)"]},{"cell_type":"code","execution_count":12,"id":"8622398f","metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1716527554146,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"8622398f"},"outputs":[],"source":["# Merge tweet data with stock price data based on Stock name\n","stock_prices['Date'] = pd.to_datetime(stock_prices['Date'])\n","tweet_data['Date'] = pd.to_datetime(tweet_data['Date'])\n","combined_data = pd.merge(stock_prices, tweet_data, on=['Stock','Date'], how='inner')"]},{"cell_type":"code","execution_count":13,"id":"4a697b2e","metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1716527554147,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"4a697b2e"},"outputs":[],"source":["X = combined_data[['sentiment', 'Open', 'Adj Close']]  # Include other features along with sentiment\n","y = combined_data['Close']"]},{"cell_type":"code","execution_count":14,"id":"5bd3896c","metadata":{"executionInfo":{"elapsed":5833,"status":"ok","timestamp":1716527559950,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"5bd3896c"},"outputs":[],"source":["\n","# Convert categorical sentiment labels to numerical values using one-hot encoding\n","X = pd.get_dummies(X, columns=['sentiment','Adj Close', 'Open'], drop_first=True)\n"]},{"cell_type":"code","execution_count":15,"id":"r-MJ6gEhXlPQ","metadata":{"executionInfo":{"elapsed":1400,"status":"ok","timestamp":1716527561324,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"r-MJ6gEhXlPQ"},"outputs":[],"source":["\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":16,"id":"BWe-MUyhtBc0","metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1716527561325,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"BWe-MUyhtBc0"},"outputs":[],"source":["# Reshape data to add sequence dimension\n","sequence_length = 10  # Example sequence length\n","def create_sequences(data, seq_length):\n","    sequences = []\n","    for i in range(len(data) - seq_length):\n","        seq = data[i:i + seq_length]\n","        sequences.append(seq)\n","    return np.array(sequences)"]},{"cell_type":"code","execution_count":17,"id":"zDkjUGCetIA5","metadata":{"executionInfo":{"elapsed":57437,"status":"ok","timestamp":1716527618742,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"zDkjUGCetIA5"},"outputs":[],"source":["X_train_seq = create_sequences(X_train.values, sequence_length)\n","y_train_seq = y_train.values[sequence_length:]\n","X_test_seq = create_sequences(X_test.values, sequence_length)\n","y_test_seq = y_test.values[sequence_length:]"]},{"cell_type":"code","execution_count":18,"id":"522d5128","metadata":{"executionInfo":{"elapsed":12619,"status":"ok","timestamp":1716527631334,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"522d5128"},"outputs":[],"source":["X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train_seq.reshape(-1, 1), dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test_seq.reshape(-1, 1), dtype=torch.float32)\n"]},{"cell_type":"code","execution_count":19,"id":"85acc6dc","metadata":{"executionInfo":{"elapsed":54,"status":"ok","timestamp":1716527631335,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"85acc6dc"},"outputs":[],"source":["# Create data loaders\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"]},{"cell_type":"code","execution_count":20,"id":"072af7b6","metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1716527631336,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"072af7b6"},"outputs":[],"source":["# Initialize LSTM model\n","input_size = X_train_seq.shape[2]\n","hidden_size = 64\n","num_layers = 2\n","output_size = 1\n","lstm_model = LSTMModel(input_size, hidden_size, num_layers, output_size)"]},{"cell_type":"code","execution_count":21,"id":"D75fWqYsdxku","metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1716527631336,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"D75fWqYsdxku"},"outputs":[],"source":["# Initialize Gru model\n","input_size = X_train_seq.shape[2]\n","hidden_size = 64\n","num_layers = 2\n","output_size = 1\n","gru_model = GRUModel(input_size, hidden_size, num_layers, output_size)"]},{"cell_type":"code","execution_count":22,"id":"m2LrQEXJeBi-","metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1716527631337,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"m2LrQEXJeBi-"},"outputs":[],"source":["# Initialize Transformer model\n","input_size = X_train_seq.shape[2]\n","hidden_size = 64\n","num_headers = 4\n","num_encoder_layers = 2\n","num_decoder_layers = 2\n","output_size = 1\n","transformer_model = TransformerModel(input_size, hidden_size, num_headers, num_encoder_layers, num_decoder_layers, output_size)"]},{"cell_type":"code","execution_count":23,"id":"6219134b","metadata":{"executionInfo":{"elapsed":1821,"status":"ok","timestamp":1716527633122,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"},"user_tz":-120},"id":"6219134b"},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n","gru_optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n","transformer_optimizer = optim.Adam(transformer_model.parameters(), lr=0.001)\n","\n","threshold = 0.5"]},{"cell_type":"code","execution_count":27,"id":"b96c3412","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b96c3412","executionInfo":{"status":"ok","timestamp":1716536553306,"user_tz":-120,"elapsed":2319147,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"}},"outputId":"f32b4671-2499-4948-cdd5-934dab920421"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 11434363.2202\n","Epoch [2/10], Loss: 11432437.5950\n","Epoch [3/10], Loss: 11430331.9378\n","Epoch [4/10], Loss: 11428285.1878\n","Epoch [5/10], Loss: 11426287.5385\n","Epoch [6/10], Loss: 11424458.0627\n","Epoch [7/10], Loss: 11422533.5552\n","Epoch [8/10], Loss: 11420961.2485\n","Epoch [9/10], Loss: 11419151.0085\n","Epoch [10/10], Loss: 11417375.4761\n","LSTM Model:\n","Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n"]}],"source":["\n","# Train model\n","train_model(lstm_model, train_loader, criterion, lstm_optimizer, num_epochs=10)\n","\n","# Evaluate model\n","evaluate_model(lstm_model, test_loader)\n","\n","predictions, actuals = evaluate_model(lstm_model, test_loader)\n","predictions_class = (predictions > threshold).astype(int)\n","actuals_binary = (actuals > 0).astype(int)\n","accuracy = accuracy_score(actuals_binary, predictions_class)\n","precision = precision_score(actuals_binary, predictions_class)\n","recall = recall_score(actuals_binary, predictions_class)\n","print(\"LSTM Model:\")\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n"]},{"cell_type":"markdown","id":"eg7w1HQjHpci","metadata":{"id":"eg7w1HQjHpci"},"source":[]},{"cell_type":"code","execution_count":30,"id":"s20_Ywq7fDUT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s20_Ywq7fDUT","executionInfo":{"status":"ok","timestamp":1716539591566,"user_tz":-120,"elapsed":620862,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"}},"outputId":"d04d1f42-f947-4516-90b1-e6f0efd2d960"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 11459132.5494\n","Epoch [2/10], Loss: 11455969.8388\n","Epoch [3/10], Loss: 11453247.1326\n","Epoch [4/10], Loss: 11450561.7688\n","Epoch [5/10], Loss: 11447612.9988\n","Epoch [6/10], Loss: 11445147.0122\n","Epoch [7/10], Loss: 11442612.8270\n","Epoch [8/10], Loss: 11440519.3640\n","Epoch [9/10], Loss: 11438273.5848\n","Epoch [10/10], Loss: 11436262.0297\n","GRU Model:\n","Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n"]}],"source":["# Train model\n","train_model(gru_model, train_loader, criterion, gru_optimizer, num_epochs=10)\n","\n","# Evaluate model\n","evaluate_model(gru_model, test_loader)\n","\n","# GRU Model Evaluation\n","predictions, actuals = evaluate_model(gru_model, test_loader)\n","predictions_class = (predictions > threshold).astype(int)\n","actuals_binary = (actuals > 0).astype(int)\n","accuracy = accuracy_score(actuals_binary, predictions_class)\n","precision = precision_score(actuals_binary, predictions_class)\n","recall = recall_score(actuals_binary, predictions_class)\n","print(\"GRU Model:\")\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)"]},{"cell_type":"code","execution_count":31,"id":"VOmbKxTjfDcq","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOmbKxTjfDcq","executionInfo":{"status":"ok","timestamp":1716541824066,"user_tz":-120,"elapsed":468135,"user":{"displayName":"Naveen Vijayasanker","userId":"03322491389827709170"}},"outputId":"032f4d5d-2c3a-4f1b-c74d-190377e3e472"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 11475297.3849\n","Epoch [2/10], Loss: 11474380.7110\n","Epoch [3/10], Loss: 11472495.1914\n","Epoch [4/10], Loss: 11473241.1761\n","Epoch [5/10], Loss: 11473160.5497\n","Epoch [6/10], Loss: 11473071.7157\n","Epoch [7/10], Loss: 11473094.4728\n","Epoch [8/10], Loss: 11472898.8207\n","Epoch [9/10], Loss: 11472698.1195\n","Epoch [10/10], Loss: 11472458.0236\n","Transformer Model:\n","Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n"]}],"source":["# Train model\n","train_model(transformer_model, train_loader, criterion, transformer_optimizer, num_epochs=10)\n","\n","# Evaluate model\n","evaluate_model(transformer_model, test_loader)\n","\n","predictions, actuals = evaluate_model(transformer_model, test_loader)\n","predictions_class = (predictions > threshold).astype(int)\n","actuals_binary = (actuals > 0).astype(int)\n","accuracy = accuracy_score(actuals_binary, predictions_class)\n","precision = precision_score(actuals_binary, predictions_class)\n","recall = recall_score(actuals_binary, predictions_class)\n","print(\"Transformer Model:\")\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}